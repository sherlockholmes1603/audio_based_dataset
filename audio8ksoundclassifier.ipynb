{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchsummary\nimport os\nimport torch\nimport torchaudio\nimport torchaudio.functional as F\nimport torchaudio.transforms as T\nfrom torch.utils.data import Dataset\nimport pandas as pd\nfrom torch import nn\nfrom torchsummary import summary\nfrom torch.utils.data import DataLoader","metadata":{"execution":{"iopub.status.busy":"2023-05-28T09:10:58.813205Z","iopub.execute_input":"2023-05-28T09:10:58.813572Z","iopub.status.idle":"2023-05-28T09:11:10.628446Z","shell.execute_reply.started":"2023-05-28T09:10:58.813542Z","shell.execute_reply":"2023-05-28T09:11:10.627063Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchsummary in /opt/conda/lib/python3.10/site-packages (1.5.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"class UrbanSoundDataset(Dataset):\n    \n    def __init__(self, annotations_file, audio_dir, transformations, sample_rate, num_samples, device):\n        self.annotations = pd.read_csv(annotations_file)\n        self.audio_dir = audio_dir\n        self.device = device\n        self.transformations = transformations.to(self.device)\n        self.sample_rate = sample_rate\n        self.num_samples = num_samples\n        \n        \n    def __len__(self):\n        return len(self.annotations)\n    \n    def __getitem__(self,index):\n        audio_sample_path = self._get_audio_sample_path(index)\n        label = self._get_audio_sample_label(index)\n        signal, sr = torchaudio.load(audio_sample_path)\n        signal = signal.to(self.device)\n        signal = self.resample(signal, sr)\n        signal = self.mix_down(signal)\n        signal = self.cut(signal)\n        signal = self.right_pad(signal)\n        signal = self.transformations(signal)\n        return signal, label\n    \n    def cut(self, signal):\n        if signal.shape[1] > self.num_samples:\n            signal = signal[:, :self.num_samples]\n        return signal\n    \n    def right_pad(self, signal):\n        length = signal.shape[1]\n        if length<self.num_samples:\n            num_missing = -length+self.num_samples\n            signal = torch.nn.functional.pad(signal, (0,num_missing))\n        return signal\n    \n    def resample(self,signal, sr):\n        if sr != self.sample_rate:\n            signal = F.resample(signal, sr, self.sample_rate)\n        return signal\n    \n    def mix_down(self, signal):\n        if signal.shape[0] > 1:\n            signal = torch.mean(signal, dim=0, keepdim=True)\n        return signal\n\n\n    \n    def _get_audio_sample_path(self, index):\n        fold = f\"fold{self.annotations.iloc[index, 5]}\"\n        path = os.path.join(self.audio_dir, fold, self.annotations.iloc[index, 0])\n        return path\n    \n    def _get_audio_sample_label(self, index):\n        return self.annotations.iloc[index, 6]","metadata":{"execution":{"iopub.status.busy":"2023-05-28T09:11:10.631021Z","iopub.execute_input":"2023-05-28T09:11:10.631523Z","iopub.status.idle":"2023-05-28T09:11:10.645894Z","shell.execute_reply.started":"2023-05-28T09:11:10.631477Z","shell.execute_reply":"2023-05-28T09:11:10.644930Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = \"cuda\"\nelse:\n    device = \"cpu\"\nprint(f\"Using {device}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-28T09:11:10.647698Z","iopub.execute_input":"2023-05-28T09:11:10.648433Z","iopub.status.idle":"2023-05-28T09:11:10.662374Z","shell.execute_reply.started":"2023-05-28T09:11:10.648401Z","shell.execute_reply":"2023-05-28T09:11:10.661024Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Using cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"BATCH_SIZE = 1024\nEPOCHS = 30\nLEARNING_RATE = 0.0001\n\nANNOTATIONS_FILE = \"/kaggle/input/urbansound8k/UrbanSound8K.csv\"\nAUDIO_DIR = \"/kaggle/input/urbansound8k\"\nSAMPLE_RATE = 22050\nNUM_SAMPLES = 22050\n\nmel_spectrogram = torchaudio.transforms.MelSpectrogram(sample_rate=SAMPLE_RATE,n_fft=1024,hop_length=512,n_mels=64)\n\nusd = UrbanSoundDataset(ANNOTATIONS_FILE,AUDIO_DIR,mel_spectrogram,SAMPLE_RATE,NUM_SAMPLES,device)\n\nprint(usd.__len__())","metadata":{"execution":{"iopub.status.busy":"2023-05-28T09:42:41.481859Z","iopub.execute_input":"2023-05-28T09:42:41.482228Z","iopub.status.idle":"2023-05-28T09:42:41.508376Z","shell.execute_reply.started":"2023-05-28T09:42:41.482199Z","shell.execute_reply":"2023-05-28T09:42:41.507468Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"8732\n","output_type":"stream"}]},{"cell_type":"code","source":"def create_data_loader(train_data, batch_size):\n    train_dataloader = DataLoader(train_data, batch_size=batch_size)\n    return train_dataloader\n\n\ndef train_single_epoch(model, data_loader, loss_fn, optimiser, device):\n    for input, target in data_loader:\n        input, target = input.to(device), target.to(device)\n\n        # calculate loss\n        prediction = model(input)\n        loss = loss_fn(prediction, target)\n\n        # backpropagate error and update weights\n        optimiser.zero_grad()\n        loss.backward()\n        optimiser.step()\n\n    print(f\"loss: {loss.item()}\")\n\n\ndef train(model, data_loader, loss_fn, optimiser, device, epochs):\n    for i in range(epochs):\n        print(f\"Epoch {i+1}\")\n        train_single_epoch(model, data_loader, loss_fn, optimiser, device)\n        print(\"---------------------------\")\n    print(\"Finished training\")","metadata":{"execution":{"iopub.status.busy":"2023-05-28T09:11:10.703444Z","iopub.execute_input":"2023-05-28T09:11:10.703746Z","iopub.status.idle":"2023-05-28T09:11:10.711690Z","shell.execute_reply.started":"2023-05-28T09:11:10.703717Z","shell.execute_reply":"2023-05-28T09:11:10.710448Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class CNNNetwork(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(in_channels=1,out_channels=16,kernel_size=3,stride=1,padding=2,bias=False),\n        nn.BatchNorm2d(16),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2))\n\n        self.conv2 = nn.Sequential(\n            nn.Conv2d(in_channels=16,out_channels=2*16,kernel_size=3,stride=1,padding=2,bias=False),\n        nn.BatchNorm2d(32),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2))\n\n        self.conv3 = nn.Sequential(\n            nn.Conv2d(in_channels=32,out_channels=4*16,kernel_size=3,stride=1,padding=2,bias=False),\n        nn.BatchNorm2d(2*32),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2))\n\n        self.conv4 = nn.Sequential(\n            nn.Conv2d(in_channels=2*32,out_channels=8*16,kernel_size=3,stride=1,padding=2,bias=False),\n        nn.BatchNorm2d(4*32),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2))\n        \n        self.flatten = nn.Flatten()\n        self.linear = nn.Linear(128*5*4,10) # 10 classes\n        self.softmax = nn.Softmax(dim=1)\n\n    def forward(self, input_data):\n        x = self.conv1(input_data)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.conv4(x)\n        x = self.flatten(x)\n        logits = self.linear(x)\n        preds = self.softmax(logits)\n\n        return preds","metadata":{"execution":{"iopub.status.busy":"2023-05-28T09:11:10.713237Z","iopub.execute_input":"2023-05-28T09:11:10.713844Z","iopub.status.idle":"2023-05-28T09:11:10.726232Z","shell.execute_reply.started":"2023-05-28T09:11:10.713810Z","shell.execute_reply":"2023-05-28T09:11:10.725237Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_dataloader = create_data_loader(usd, BATCH_SIZE)\n\n# construct model and assign it to device\ncnn = CNNNetwork().to(device)\nprint(cnn)\n\n# initialise loss funtion + optimiser\nloss_fn = nn.CrossEntropyLoss()\noptimiser = torch.optim.Adam(cnn.parameters(),\n                             lr=LEARNING_RATE)\n\n# train model\ntrain(cnn, train_dataloader, loss_fn, optimiser, device, EPOCHS)\n\n# save model\ntorch.save(cnn.state_dict(), \"feedforwardnet.pth\")\nprint(\"Trained feed forward net saved at feedforwardnet.pth\")","metadata":{"execution":{"iopub.status.busy":"2023-05-28T09:11:10.727915Z","iopub.execute_input":"2023-05-28T09:11:10.728255Z","iopub.status.idle":"2023-05-28T09:42:08.298445Z","shell.execute_reply.started":"2023-05-28T09:11:10.728224Z","shell.execute_reply":"2023-05-28T09:42:08.297430Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"CNNNetwork(\n  (conv1): Sequential(\n    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), bias=False)\n    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (conv2): Sequential(\n    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), bias=False)\n    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (conv3): Sequential(\n    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), bias=False)\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (conv4): Sequential(\n    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), bias=False)\n    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (linear): Linear(in_features=2560, out_features=10, bias=True)\n  (softmax): Softmax(dim=1)\n)\nEpoch 1\nloss: 2.2576992511749268\n---------------------------\nEpoch 2\nloss: 2.2222869396209717\n---------------------------\nEpoch 3\nloss: 2.1570281982421875\n---------------------------\nEpoch 4\nloss: 2.141649007797241\n---------------------------\nEpoch 5\nloss: 2.0777196884155273\n---------------------------\nEpoch 6\nloss: 2.1053617000579834\n---------------------------\nEpoch 7\nloss: 2.0574910640716553\n---------------------------\nEpoch 8\nloss: 2.040376901626587\n---------------------------\nEpoch 9\nloss: 2.0247035026550293\n---------------------------\nEpoch 10\nloss: 2.0025827884674072\n---------------------------\nEpoch 11\nloss: 1.971632480621338\n---------------------------\nEpoch 12\nloss: 1.9582648277282715\n---------------------------\nEpoch 13\nloss: 1.945001244544983\n---------------------------\nEpoch 14\nloss: 1.954203486442566\n---------------------------\nEpoch 15\nloss: 1.9683873653411865\n---------------------------\nEpoch 16\nloss: 1.9252238273620605\n---------------------------\nEpoch 17\nloss: 1.9218542575836182\n---------------------------\nEpoch 18\nloss: 1.888980746269226\n---------------------------\nEpoch 19\nloss: 1.9323523044586182\n---------------------------\nEpoch 20\nloss: 1.8861744403839111\n---------------------------\nEpoch 21\nloss: 1.8834351301193237\n---------------------------\nEpoch 22\nloss: 1.8962420225143433\n---------------------------\nEpoch 23\nloss: 1.8816958665847778\n---------------------------\nEpoch 24\nloss: 1.855993628501892\n---------------------------\nEpoch 25\nloss: 1.8596372604370117\n---------------------------\nEpoch 26\nloss: 1.8536893129348755\n---------------------------\nEpoch 27\nloss: 1.8495174646377563\n---------------------------\nEpoch 28\nloss: 1.8691842555999756\n---------------------------\nEpoch 29\nloss: 1.844751000404358\n---------------------------\nEpoch 30\nloss: 1.82810640335083\n---------------------------\nFinished training\nTrained feed forward net saved at feedforwardnet.pth\n","output_type":"stream"}]},{"cell_type":"code","source":"# train model\ntrain(cnn, train_dataloader, loss_fn, optimiser, device, EPOCHS)\n\n# save model\ntorch.save(cnn.state_dict(), \"feedforwardnet.pth\")\nprint(\"Trained feed forward net saved at feedforwardnet.pth\")","metadata":{"execution":{"iopub.status.busy":"2023-05-28T09:43:06.116893Z","iopub.execute_input":"2023-05-28T09:43:06.117491Z","iopub.status.idle":"2023-05-28T10:13:00.219573Z","shell.execute_reply.started":"2023-05-28T09:43:06.117458Z","shell.execute_reply":"2023-05-28T10:13:00.218337Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch 1\nloss: 1.8331711292266846\n---------------------------\nEpoch 2\nloss: 1.8579210042953491\n---------------------------\nEpoch 3\nloss: 1.8244266510009766\n---------------------------\nEpoch 4\nloss: 1.834548830986023\n---------------------------\nEpoch 5\nloss: 1.8366326093673706\n---------------------------\nEpoch 6\nloss: 1.822311282157898\n---------------------------\nEpoch 7\nloss: 1.8178892135620117\n---------------------------\nEpoch 8\nloss: 1.8496674299240112\n---------------------------\nEpoch 9\nloss: 1.8059686422348022\n---------------------------\nEpoch 10\nloss: 1.8102777004241943\n---------------------------\nEpoch 11\nloss: 1.8371118307113647\n---------------------------\nEpoch 12\nloss: 1.7984271049499512\n---------------------------\nEpoch 13\nloss: 1.8216724395751953\n---------------------------\nEpoch 14\nloss: 1.796482801437378\n---------------------------\nEpoch 15\nloss: 1.785979986190796\n---------------------------\nEpoch 16\nloss: 1.7890472412109375\n---------------------------\nEpoch 17\nloss: 1.8232446908950806\n---------------------------\nEpoch 18\nloss: 1.7883273363113403\n---------------------------\nEpoch 19\nloss: 1.7897708415985107\n---------------------------\nEpoch 20\nloss: 1.786129117012024\n---------------------------\nEpoch 21\nloss: 1.7895960807800293\n---------------------------\nEpoch 22\nloss: 1.8075441122055054\n---------------------------\nEpoch 23\nloss: 1.7917537689208984\n---------------------------\nEpoch 24\nloss: 1.781153917312622\n---------------------------\nEpoch 25\nloss: 1.7948869466781616\n---------------------------\nEpoch 26\nloss: 1.7713830471038818\n---------------------------\nEpoch 27\nloss: 1.784925937652588\n---------------------------\nEpoch 28\nloss: 1.7849907875061035\n---------------------------\nEpoch 29\nloss: 1.7809218168258667\n---------------------------\nEpoch 30\nloss: 1.7720229625701904\n---------------------------\nFinished training\nTrained feed forward net saved at feedforwardnet.pth\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}